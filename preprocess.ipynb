{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_dir = 'Fish_Dataset' \n",
    "\n",
    "path = []\n",
    "label = []\n",
    "\n",
    "\n",
    "for dir_name, _, filenames in os.walk(fish_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.png') and 'GT' not in dir_name:\n",
    "            \n",
    "            folder_name = dir_name.split(os.sep)[-1]\n",
    "            \n",
    "            label.append(folder_name)\n",
    "            path.append(os.path.join(dir_name, filename))\n",
    "\n",
    "\n",
    "data = pd.DataFrame({'path': path, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'].unique() # Subclasses of the categorical variable \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plt.figure(figsize=(15,12))\n",
    "for unique_label in data['label'].unique():\n",
    "    plt.subplot(3, 3, idx+1)\n",
    "    plt.imshow(plt.imread(data[data['label']==unique_label].iloc[0,0]))\n",
    "    plt.title(unique_label)\n",
    "    plt.axis('off')\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into training, validating and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split \n",
    "x_train, x_test = train_test_split(data, test_size=0.3, shuffle=True, random_state=30)\n",
    "x_train, x_val = train_test_split(x_train, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of training data\", x_train.shape)\n",
    "print(\"Shape of test data\", x_test.shape)\n",
    "print(\"Shape of validation data\", x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels in sorted order\n",
    "labels = ['Black Sea Sprat', 'Gilt-Head Bream', 'Hourse Mackerel',\n",
    "          'Red Mullet', 'Red Sea Bream', 'Sea Bass', 'Shrimp',\n",
    "          'Striped Red Mullet', 'Trout']\n",
    "unique_labels = sorted(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=(0.8, 1.2)\n",
    ")\n",
    "\n",
    "train = image_data_generator.flow_from_dataframe(dataframe=x_train, x_col='path', y_col='label', target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='rgb', class_mode='categorical', batch_size=BATCH_SIZE, shuffle = True, class_names=unique_labels)\n",
    "test = image_data_generator.flow_from_dataframe(dataframe=x_test, x_col='path', y_col='label', target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='rgb', class_mode='categorical', batch_size=BATCH_SIZE, shuffle = False, class_names=unique_labels)\n",
    "val = image_data_generator.flow_from_dataframe(dataframe=x_val, x_col='path', y_col='label', target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='rgb', class_mode='categorical', batch_size=BATCH_SIZE, shuffle = False, class_names=unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "mlp_model.add(tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
    "\n",
    "# Flatten layer\n",
    "mlp_model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# 3 Hidden Layers with (256, 256, 128) neurons and relu activation function\n",
    "mlp_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "# Dropout layer to reduce overfitting\n",
    "mlp_model.add(tf.keras.layers.Dropout(0.4))\n",
    "mlp_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "mlp_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer with 9 neurons and softmax activation function\n",
    "mlp_model.add(tf.keras.layers.Dense(9, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='rmsprop',\n",
    "                 metrics=['acc'])\n",
    "\n",
    "mlp_model.fit(train,validation_data=val,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mlp_model.evaluate(test)\n",
    "print(\"Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlp_model.predict(test)\n",
    "pred=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get true labels from the test dataset\n",
    "y_true = []\n",
    "for _, labels in test:  # Iterate over the test dataset\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))  # Convert one-hot to class indices\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_names = sorted(set(x_test['label'].values))  # Replace with actual class names if available\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate 45 degrees and align to the right\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    'label': y_true,\n",
    "    'pred': pred\n",
    "})\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(pred_df['label'], pred_df['pred'], target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will loss the spatial features of the image when we flattening the image to 2D vector, we will loss a lot of information and the network does not relate the pixel values to each other when it is trying to find patterns thats why we get a very bad accuracy when we use MLP in such problem.\n",
    "\n",
    "Why??\n",
    "\n",
    "1. Loss of information\n",
    "\n",
    "* When we Flatten the image to be a 1D vector, the pixel values that present the fish will be distributed in a certain way in the vector lets say in the left side of the image, if we have a new image that has the same object but in different location in the image, the neural network will not recognize it because different neurons need to fires in order to recognize the fish, the neural network will have no idea that this is the same fish. But why it does better than that on the MNIST data set, because MNIST data are well prepared for this task. The MLP will not learn the fish shape.\n",
    "\n",
    "2. Very large number of parameters\n",
    "\n",
    "* Another problem with the MLP is that it is an Fully connected layer, where every node in the layer is connected to all nodes of the previous layer and all nodes in the next layer. You saw that with this simple network we have more that 24 million parameters to learn, with more complex network and larger image size we will end up with billions of parameters to train and it is very computationally expensive.\n",
    "\n",
    "Next we will use Convolutional neural networks to train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model \n",
    "cnn_model = tf.keras.models.Sequential()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Conv layer: 32 filters of size (3, 3), with strides = 1 and relu activation\n",
    "cnn_model.add(tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
    "cnn_model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Conv layer: 64 filters of size (3, 3), with strides = 1 and relu activation\n",
    "cnn_model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1, \n",
    "                                    activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Conv layer: 128 filters of size (3, 3), with strides = 1 and relu activation\n",
    "cnn_model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1, \n",
    "                                    activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Conv layer: 128 filters of size (3, 3), with strides = 1 and relu activation\n",
    "cnn_model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=1, \n",
    "                                    activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Conv layer: 256 filters of size (3, 3), with strides = 1 and relu activation\n",
    "cnn_model.add(tf.keras.layers.Conv2D(256, kernel_size=(3, 3), strides=1, \n",
    "                                    activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "# Global Average Pooling\n",
    "cnn_model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "# Fully connected layer with 256 units and relu activation\n",
    "cnn_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Dropout layer to lower the overfitting with dropout rate of 0.4\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "# Fully connected layer with 9 units and softmax activation\n",
    "cnn_model.add(tf.keras.layers.Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='rmsprop',\n",
    "                 metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(train, validation_data=val, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(history.epoch, train_acc, label='Training Accuracy')\n",
    "plt.plot(history.epoch, val_acc, label='Validation Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cnn_model.evaluate(test)\n",
    "print(\"Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn_model.predict(test)\n",
    "pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels from the test dataset\n",
    "y_true = []\n",
    "for _, labels in test:  # Iterate over the test dataset\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))  # Convert one-hot to class indices\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "class_names = sorted(set(x_test['label'].values))  # Replace with actual class names if available\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate 45 degrees and align to the right\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    'label': y_true,\n",
    "    'pred': pred\n",
    "})\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(pred_df['label'], pred_df['pred'], target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
